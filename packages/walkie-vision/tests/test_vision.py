import json
import os
from datetime import datetime

import cv2
import numpy as np
import pytest

from walkie_vision.detector import VisionDetector
from walkie_vision.encoder import VisionEncoder


@pytest.fixture
def test_data_path():
    """‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Directory ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Test"""
    return os.path.join(os.path.dirname(__file__), "data")


@pytest.fixture
def output_path():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Directory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£ Test"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    path = os.path.join(os.path.dirname(__file__), "outputs", timestamp)
    os.makedirs(path, exist_ok=True)
    return path


@pytest.fixture
def vision_detector():
    """‡πÇ‡∏´‡∏•‡∏î Detector ‡∏à‡∏£‡∏¥‡∏á (‡∏£‡∏∏‡πà‡∏ô Standard Detection)"""
    return VisionDetector(
        yolo_checkpoint="models/yolo26x.pt",
        device="cpu",  # ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô cuda ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ GPU ‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏ó‡∏™‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á
    )


@pytest.fixture
def vision_encoder():
    """‡πÇ‡∏´‡∏•‡∏î Encoder ‡∏à‡∏£‡∏¥‡∏á (‡πÉ‡∏ä‡πâ CPU)"""
    return VisionEncoder(device="cpu")


def test_vision_integration_with_real_file(
    vision_detector, vision_encoder, test_data_path, output_path
):
    """
    Integration Test ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Artifacts)
    ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô YOLO-only Segmentation
    """
    img_path = os.path.join(test_data_path, "test_room_2.jpg")

    if not os.path.exists(img_path):
        pytest.skip(f"Test file not found at {img_path}. Please add a sample image.")

    frame = cv2.imread(img_path)

    # 1. ‡∏£‡∏±‡∏ô Detector (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô YOLO-seg ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏•‡πâ‡∏ß ‡∏à‡∏∞‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏Å)
    objects = vision_detector.get_segmented_objects(frame)

    assert len(objects) > 0, "Detector should find at least one object"

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° List ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö Metadata ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON
    test_results_summary = []

    # 2. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
    for i, obj in enumerate(objects):
        # ‡∏£‡∏±‡∏ô Encoder (‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ Caption ‡∏Ñ‡∏ß‡∏£‡∏à‡∏∞‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡πâ‡∏ß)
        caption, embedding = vision_encoder.encode_object(obj["image"])

        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà Crop ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
        crop_filename = f"obj_{i}_{obj['yolo_class']}.jpg"
        cv2.imwrite(os.path.join(output_path, crop_filename), obj["image"])

        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á Summary
        test_results_summary.append(
            {
                "index": i,
                "class": obj["yolo_class"],
                "caption": caption,
                "crop_path": crop_filename,
                "embedding_sample": embedding[:5],
            }
        )

        # Test assertions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å
        if i == 0:
            assert len(caption) > 0
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î Embedding (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ clip-ViT-B-32 ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô 512)
            assert len(embedding) == 512

    # 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Metadata ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON
    with open(os.path.join(output_path, "summary.json"), "w", encoding="utf-8") as f:
        json.dump(test_results_summary, f, indent=4, ensure_ascii=False)

    print(f"\n‚úÖ Test artifacts saved to: {output_path}")
    print(f"üìä Total objects found: {len(objects)}")
