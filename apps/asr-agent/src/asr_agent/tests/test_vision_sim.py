import os
import time

import cv2
import pytest

from asr_agent.core.orchestrator import AgentOrchestrator
from asr_agent.tools.vision import analyze_and_store_objects, get_current_view

DEBUG_IMAGE_PATH = "debug_sim_view.jpg"


def test_vision_end_to_end_with_sim():
    # --- STEP 0: Cleanup ---
    if os.path.exists(DEBUG_IMAGE_PATH):
        os.remove(DEBUG_IMAGE_PATH)

    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Orchestrator
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÉ‡∏ô __init__ ‡∏Ç‡∏≠‡∏á Orchestrator ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Zenoh 7447 ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
    orchestrator = AgentOrchestrator()

    # ‡∏£‡∏≠‡πÉ‡∏´‡πâ Zenoh ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏° Streaming (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Zenoh)
    print("‚è≥ Waiting for Zenoh discovery...")
    time.sleep(2)

    user_command = "Walkie, look at the table in front of you and tell me what you see."
    print(f"\nüöÄ [Command]: {user_command}")

    # --- STEP 1: Planning ---
    response = orchestrator.run_command(user_command)
    tool_calls = orchestrator.client.parse_tool_calls(response)

    assert len(tool_calls) >= 2, (
        "AI failed to plan the vision pipeline (Capture -> Analyze)"
    )

    # --- STEP 2: Capture (Execution) ---
    print("\nüì∏ Capturing frame from Gazebo via Zenoh (Port 7447)...")
    capture_result = get_current_view.invoke({})

    if "Error" in capture_result:
        pytest.fail(f"Zenoh Camera Capture Failed: {capture_result}")

    # --- STEP 3: Visualization Check ---
    assert os.path.exists(DEBUG_IMAGE_PATH), "Image file was not saved!"
    img = cv2.imread(DEBUG_IMAGE_PATH)
    assert img is not None, "Saved image is corrupted"

    h, w, _ = img.shape
    print(f"üñºÔ∏è  Real-time Frame captured: {w}x{h}")

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ "‡πÄ‡∏´‡πá‡∏ô" ‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ó‡∏™ (‡∏à‡∏∞‡πÇ‡∏ä‡∏ß‡πå 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏•‡πâ‡∏ß‡∏õ‡∏¥‡∏î)
    if os.environ.get("DISPLAY"):  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏ä‡∏ß‡πå‡πÑ‡∏´‡∏°
        cv2.imshow("Test Vision View", img)
        cv2.waitKey(2000)
        cv2.destroyAllWindows()

    # --- STEP 4: Analysis ---
    print("\nüîç Running YOLO Analysis (on RTX 5090)...")
    analysis_result = analyze_and_store_objects.invoke({})
    print(f"üìä [Analysis Output]: {analysis_result}")

    assert "stored" in analysis_result.lower()
    print("\n‚ú® Vision Pipeline is working perfectly with Zenoh & Live Sim!")
