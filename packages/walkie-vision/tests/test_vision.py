import json
import os
from datetime import datetime

import cv2
import numpy as np
import pytest

from walkie_vision.detector import VisionDetector
from walkie_vision.encoder import VisionEncoder


@pytest.fixture
def test_data_path():
    """à¸Šà¸µà¹‰à¹„à¸›à¸¢à¸±à¸‡ Directory à¸—à¸µà¹ˆà¹€à¸à¹‡à¸šà¸ à¸²à¸à¸ªà¸³à¸«à¸£à¸±à¸š Test"""
    return os.path.join(os.path.dirname(__file__), "data")


@pytest.fixture
def output_path():
    """à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸Šà¸µà¹‰à¹„à¸›à¸¢à¸±à¸‡ Directory à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸à¸²à¸£ Test"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    path = os.path.join(os.path.dirname(__file__), "outputs", timestamp)
    os.makedirs(path, exist_ok=True)
    return path


@pytest.fixture
def vision_detector():
    """à¹‚à¸«à¸¥à¸” Detector à¸ˆà¸£à¸´à¸‡ (à¹ƒà¸Šà¹‰ CPU à¹€à¸à¸·à¹ˆà¸­à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š)"""
    return VisionDetector(
        sam_checkpoint="models/sam2_b.pt",
        yolo_checkpoint="models/yolov8x.pt",
        device="cpu",
    )


@pytest.fixture
def vision_encoder():
    """à¹‚à¸«à¸¥à¸” Encoder à¸ˆà¸£à¸´à¸‡ (à¹ƒà¸Šà¹‰ CPU)"""
    return VisionEncoder(device="cpu")


def test_vision_integration_with_real_file(
    vision_detector, vision_encoder, test_data_path, output_path
):
    """
    Integration Test à¸à¸£à¹‰à¸­à¸¡à¸£à¸°à¸šà¸šà¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ (Artifacts)
    """
    img_path = os.path.join(test_data_path, "test_room.jpg")

    if not os.path.exists(img_path):
        pytest.skip(f"Test file not found at {img_path}. Please add a sample image.")

    frame = cv2.imread(img_path)

    # 1. à¸£à¸±à¸™ Detector
    objects = vision_detector.get_segmented_objects(frame)

    assert len(objects) > 0, "Detector should find at least one object"

    # à¹€à¸•à¸£à¸µà¸¢à¸¡ List à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸š Metadata à¹€à¸à¸·à¹ˆà¸­à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸›à¹‡à¸™ JSON
    test_results_summary = []

    # 2. à¸§à¸™à¸¥à¸¹à¸›à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸‚à¸­à¸‡à¸—à¸¸à¸à¸§à¸±à¸•à¸–à¸¸à¸—à¸µà¹ˆà¹€à¸ˆà¸­ (à¸«à¸£à¸·à¸­à¸ˆà¸°à¹€à¸¥à¸·à¸­à¸à¹à¸„à¹ˆ 5 à¸•à¸±à¸§à¹à¸£à¸à¹€à¸à¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¹„à¸§)
    for i, obj in enumerate(objects):
        # à¸£à¸±à¸™ Encoder
        caption, embedding = vision_encoder.encode_object(obj["image"])

        # à¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸à¸§à¸±à¸•à¸–à¸¸à¸—à¸µà¹ˆ Crop à¸­à¸­à¸à¸¡à¸²
        crop_filename = f"obj_{i}_{obj['yolo_class']}.jpg"
        cv2.imwrite(os.path.join(output_path, crop_filename), obj["image"])

        # à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¥à¸‡ Summary
        test_results_summary.append(
            {
                "index": i,
                "class": obj["yolo_class"],
                "caption": caption,
                "crop_path": crop_filename,
                "embedding_sample": embedding[:5],  # à¹€à¸à¹‡à¸šà¹à¸„à¹ˆ 5 à¸„à¹ˆà¸²à¹à¸£à¸à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
            }
        )

        # Test assertions à¸ªà¸³à¸«à¸£à¸±à¸šà¸•à¸±à¸§à¹à¸£à¸ (à¸•à¸²à¸¡à¹€à¸”à¸´à¸¡)
        if i == 0:
            assert len(caption) > 0
            assert len(embedding) == 512

    # 3. à¸šà¸±à¸™à¸—à¸¶à¸ Metadata à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œ JSON
    with open(os.path.join(output_path, "summary.json"), "w", encoding="utf-8") as f:
        json.dump(test_results_summary, f, indent=4, ensure_ascii=False)

    print(f"\nâœ… Test artifacts saved to: {output_path}")
    print(f"ğŸ“Š Total objects found: {len(objects)}")
