import json
import os
from datetime import datetime

import cv2
import numpy as np
import pytest

from walkie_vision.detector import VisionDetector
from walkie_vision.encoder import VisionEncoder


@pytest.fixture
def test_data_path():
    """à¸Šà¸µà¹‰à¹„à¸›à¸¢à¸±à¸‡ Directory à¸—à¸µà¹ˆà¹€à¸à¹‡à¸šà¸ à¸²à¸à¸ªà¸³à¸«à¸£à¸±à¸š Test"""
    return os.path.join(os.path.dirname(__file__), "data")


@pytest.fixture
def output_path():
    """à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸Šà¸µà¹‰à¹„à¸›à¸¢à¸±à¸‡ Directory à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸à¸²à¸£ Test"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    path = os.path.join(os.path.dirname(__file__), "outputs", timestamp)
    os.makedirs(path, exist_ok=True)
    return path


@pytest.fixture
def vision_detector():
    """à¹‚à¸«à¸¥à¸” Detector à¸ˆà¸£à¸´à¸‡ (à¸­à¸±à¸›à¹€à¸à¸£à¸”à¹€à¸›à¹‡à¸™ CUDA à¸ªà¸³à¸«à¸£à¸±à¸š 5090)"""
    return VisionDetector(
        yolo_checkpoint="models/yolo26x.pt",  # à¸«à¸£à¸·à¸­ yolo26x.pt à¸•à¸²à¸¡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸•à¸±à¹‰à¸‡à¸Šà¸·à¹ˆà¸­à¹„à¸§à¹‰
        device="cuda",
    )


@pytest.fixture
def vision_encoder():
    """à¹‚à¸«à¸¥à¸” Encoder à¸ˆà¸£à¸´à¸‡ (à¸­à¸±à¸›à¹€à¸à¸£à¸”à¹€à¸›à¹‡à¸™ CUDA à¹€à¸à¸·à¹ˆà¸­à¸—à¸³ Batch Processing)"""
    return VisionEncoder(device="cuda")


def test_vision_integration_with_real_file(
    vision_detector, vision_encoder, test_data_path, output_path
):
    """
    Integration Test: à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™ High-Performance Batch Processing
    """
    img_path = os.path.join(test_data_path, "test_room_3.jpg")

    if not os.path.exists(img_path):
        pytest.skip(f"Test file not found at {img_path}.")

    frame = cv2.imread(img_path)

    # 1. à¸£à¸±à¸™ Detector à¹€à¸à¸·à¹ˆà¸­à¸«à¸² Bounding Boxes à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸ à¸²à¸à¹€à¸”à¸µà¸¢à¸§
    objects = vision_detector.get_segmented_objects(frame)
    assert len(objects) > 0, "Detector should find at least one object"

    # --- ğŸ”¥ BATCH PROCESSING START ---

    # à¸£à¸§à¸šà¸£à¸§à¸¡à¸ à¸²à¸à¸—à¸¸à¸à¸¥à¸¹à¸à¸—à¸µà¹ˆ YOLO à¸•à¸±à¸”à¸¡à¸²à¹„à¸”à¹‰à¹€à¸‚à¹‰à¸²à¹€à¸›à¹‡à¸™ List à¹€à¸”à¸µà¸¢à¸§
    images_to_process = [obj["image"] for obj in objects]

    # à¸ªà¹ˆà¸‡à¹€à¸‚à¹‰à¸² GPU à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥ Caption à¹à¸¥à¸° Embedding à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸„à¸³à¸ªà¸±à¹ˆà¸‡à¹€à¸”à¸µà¸¢à¸§
    print(
        f"\nğŸš€ Processing {len(images_to_process)} objects in parallel on RTX 5090..."
    )
    all_captions, all_embeddings = vision_encoder.encode_batch(images_to_process)

    # --- BATCH PROCESSING END ---

    test_results_summary = []

    # 2. à¸ˆà¸±à¸”à¹€à¸à¹‡à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ (à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™ I/O à¹€à¸¥à¸¢à¸•à¹‰à¸­à¸‡à¸§à¸™à¸¥à¸¹à¸›à¹€à¸‹à¸Ÿà¹„à¸Ÿà¸¥à¹Œà¸›à¸à¸•à¸´)
    for i, obj in enumerate(objects):
        caption = all_captions[i]
        embedding = all_embeddings[i]

        # à¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸à¸§à¸±à¸•à¸–à¸¸à¸—à¸µà¹ˆ Crop à¸­à¸­à¸à¸¡à¸²
        crop_filename = f"obj_{i}_{obj['yolo_class']}.jpg"
        cv2.imwrite(os.path.join(output_path, crop_filename), obj["image"])

        # à¸£à¸§à¸šà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¥à¸‡ Summary
        test_results_summary.append(
            {
                "index": i,
                "class": obj["yolo_class"],
                "caption": caption,
                "crop_path": crop_filename,
                "embedding_sample": embedding[:5],  # à¹€à¸à¹‡à¸š 5 à¸„à¹ˆà¸²à¹à¸£à¸à¸”à¸¹à¹€à¸›à¹‡à¸™à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡
            }
        )

        # Assertion à¹€à¸Šà¹‡à¸„à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¹€à¸šà¸·à¹‰à¸­à¸‡à¸•à¹‰à¸™
        if i == 0:
            assert len(caption) > 0
            assert len(embedding) == 512

    # 3. à¸šà¸±à¸™à¸—à¸¶à¸ Metadata à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œ JSON
    with open(os.path.join(output_path, "summary.json"), "w", encoding="utf-8") as f:
        json.dump(test_results_summary, f, indent=4, ensure_ascii=False)

    print(f"âœ… Test completed!")
    print(f"ğŸ“Š Objects: {len(objects)} | Output: {output_path}")
